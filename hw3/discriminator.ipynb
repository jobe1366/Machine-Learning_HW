{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUXoMKBNL2BB"
   },
   "source": [
    "\n",
    "\n",
    "## _design a discriminator by Naive Bayes model_\n",
    "\n",
    "- _assume that we know distribution of data is Gaussian_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzYY1KuUPu2Z"
   },
   "source": [
    "###  _preprocessing and Reading the Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3wyhQpoQQgQ0",
    "outputId": "8f4cdba2-a3f2-4f35-cada-696f1d225c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our dataset has 4 features. for more information about data surf the web\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# store the feature matrix (X) and response vector (y) \n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(\"our dataset has \" + str(X.shape[1]) + \" features. for more information about data surf the web\")\n",
    "\n",
    "# splitting X and y into training and testing sets\n",
    "#you can change the test size, fit model with more or less data and see results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fq4rKK30R9fz"
   },
   "source": [
    "##### _print the number of train and test data and number of classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQy7kw4pSR8l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train data is : 90\n",
      "the number of test data is : 60\n",
      "there are 3 different classes in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of train data is : \" + str(X_train.shape[0]))\n",
    "print(\"the number of test data is : \" + str(X_test.shape[0]))\n",
    "print(\"there are \" + str(len(set(y_train))) + \" different classes in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDB-hbPVSpHt"
   },
   "source": [
    "### **Training a model** (_Assume that the data follows a Gaussian distribution_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAlhGi06Voxt"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes model implementation\n",
    "\n",
    "\n",
    "class Bayes():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.distribution_params = None\n",
    "    \n",
    "    def gaussian(self,x,u,var):\n",
    "        return (1/np.sqrt(2*np.pi*var)) * np.exp(-((x-u)**2)/(2*var))\n",
    "    \n",
    "    def _compute_priors(self,yt):\n",
    "\n",
    "        classes = np.unique(yt)\n",
    "        targets = np.asarray(yt)\n",
    "        self.num_classes = (len(classes))\n",
    "        # compute prior probabilities\n",
    "        priors = np.zeros((len(classes),))\n",
    "        for i in range(len(classes)):\n",
    "            priors[i] = yt[yt==classes[i]].shape[0]/targets.shape[0]\n",
    "\n",
    "        return priors\n",
    "\n",
    "    def _estimate_pdf_dist(self, xt,yt):\n",
    "        classes = np.unique(yt)\n",
    "        targets = np.asarray(yt)\n",
    "        distribution_params = np.zeros((len(classes),xt.shape[1],2))\n",
    "        # compute class conditional pdfs\n",
    "        for i in range(len(classes)):\n",
    "            x = xt[yt==classes[i]]\n",
    "            for j in range(x.shape[1]):\n",
    "                distribution_params[i,j,0] = np.mean(x[:,j])\n",
    "                distribution_params[i,j,1] = np.var(x[:,j])\n",
    "        return distribution_params\n",
    "    \n",
    "    def train(self,xt,yt):\n",
    "        self.priors = self._compute_priors(yt)\n",
    "        self.distribution_params = self._estimate_pdf_dist(xt,yt)\n",
    "\n",
    "    def predict(self,sample):\n",
    "        # compute posterior probabilities\n",
    "        posteriors = np.zeros((self.num_classes,))\n",
    "        for i in range(self.num_classes):\n",
    "            likelihoods = np.asarray([self.gaussian(x,u,var) for x,u,var in zip(sample,self.distribution_params[i,:,0],self.distribution_params[i,:,1]) ])\n",
    "            posteriors[i] = self.priors[i]* np.prod(likelihoods)\n",
    "        # return argument of maximum posterior\n",
    "        return np.argmax(posteriors)\n",
    "\n",
    "\n",
    "model = Bayes()\n",
    "model.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkv9HCmSWAk0"
   },
   "source": [
    "#### _testing and accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ordqnzrKXcLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:95.08  Recall:95.0  F1-score:95.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    predictions.append(model.predict(X_test[i,:]))\n",
    "    \n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\" + str(round(prec*100,2)) + \"Recall:\"  +  str(round(rcall*100,2))  + \"F1-score:\" +str(round(f1*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V49EZ73XsvG"
   },
   "source": [
    "\n",
    "### _classification using SVM and MLP_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VftAlrbXZ-Nn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:98.41%  Recall:98.33%  F1-score:98.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#train svm model\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "# predict\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# evaluate performance\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYJlUDsGaGQT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:100.0%  Recall:100.0%  F1-score:100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#use two hidden layers \n",
    "#train multi layer perceptron\n",
    "\n",
    "neural_model = MLPClassifier(hidden_layer_sizes=(256,100 ), activation='logistic',max_iter=1000)\n",
    "neural_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = neural_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_bh4KyklqFA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYGlkDuckgmz"
   },
   "source": [
    "# _Repeat all steps for new dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d626_2ecknMc"
   },
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "# store the feature matrix (X) and response vector (y) \n",
    "X = wine.data \n",
    "y = wine.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3ihimJ_lBJq"
   },
   "source": [
    "### _assume that we know distribution of data is Gaussian_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i8GbQt9lPJO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# training the model on training set \n",
    "\n",
    "# write your code here :\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnkJltLll0qD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:98.66%  Recall:98.61%  F1-score:98.61%\n"
     ]
    }
   ],
   "source": [
    "#write your code here :\n",
    "predictions = gnb.predict(X_test)\n",
    "\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24nscd6El30c"
   },
   "source": [
    "##### _classification using SVM and MLP_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cw27u1bmBWE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:70.0%  Recall:70.83%  F1-score:69.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#train svm model\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqS7kFEqmEMG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:94.74%  Recall:94.44%  F1-score:94.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#train multi layer perceptron\n",
    "\n",
    "neural_model = MLPClassifier(hidden_layer_sizes=(256,100 ), activation='logistic',max_iter=1000)\n",
    "neural_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = neural_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw54ZdjmlsjN"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4-project",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
